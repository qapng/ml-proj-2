{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets\n",
    "\n",
    "This is a sample code to assist you with vectorising the 'Train' dataset for your assignment 2.\n",
    "\n",
    "First we read the CSV datafiles (Train and Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "# test_data = pd.read_csv(\"Test.csv\", sep=',')\n",
    "\n",
    "big_data = pd.read_csv(\"Train.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = [x[0] for x in big_data[['text']].values]\n",
    "X_train_raw = [item.lower() for item in X_train_raw]\n",
    "X_train_raw = [re.sub('((www.[^s]+)|(https?://[^s]+))',' ',item) for item in X_train_raw]\n",
    "# X_train_raw = [re.sub('[0-9]+', \"\", item) for item in X_train_raw]\n",
    "X_train_raw = [re.sub('[^a-z ]+', \"\", item) for item in X_train_raw]\n",
    "\n",
    "# stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "#              'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "#              'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "#              'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "#              'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "#              'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "#              'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "#              'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "#              'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "#              't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "#              'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "#              'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "#              'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "#              'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "#              \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "# STOPWORDS = set(stopwordlist)\n",
    "# X_train_raw = [\" \".join([word for word in str(item).split() if word not in STOPWORDS]) for item in X_train_raw]\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "X_train_raw = [tokenizer.tokenize(item) for item in X_train_raw]\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "def stem_string(arr):\n",
    "    arr = [ps.stem(item) for item in arr]\n",
    "    return arr\n",
    "X_train_raw = [stem_string(item) for item in X_train_raw]\n",
    "\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "def lemmatize_string(arr):\n",
    "    arr = [lm.lemmatize(item) for item in arr]\n",
    "    return arr\n",
    "\n",
    "X_train_raw = [lemmatize_string(item) for item in X_train_raw]\n",
    "X_train_raw = [' '.join(item) for item in X_train_raw]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate the tweet text and the label (sentiment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 21802\n"
     ]
    }
   ],
   "source": [
    "#separating instance and label for Train\n",
    "# X = [x[0] for x in big_data[['text']].values]\n",
    "y = [x[0] for x in big_data[['sentiment']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Train length:\",len(X_train_raw))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_raw,y,test_size = 0.05, random_state =26105111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is anybodi go to the radio station tomorrow to see shawn me and my friend may go but we would like to make new friendsmeet there\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet\n",
    "print(X_train_raw[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words (BoW)\n",
    "In this approach, we use the **CountVectorizer** library to separate all the words in the Train corpus (dataset). These words are then used as the 'vectors' or 'features' to represent each instance (Tweet) in `Train` and `Test` datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using BoW): (20711, 30126)\n",
      "Test feature space size (using BoW): (1091, 30126)\n"
     ]
    }
   ],
   "source": [
    "BoW_vectorizer = CountVectorizer()\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Train dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Train feature space size (using BoW):\",X_train_BoW.shape)\n",
    "print(\"Test feature space size (using BoW):\",X_test_BoW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each row is a list of tuples with the vector_id (word_id in the vocabulary) and the number of times it repeated in that given instance (tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16557)\t1\n",
      "  (0, 10987)\t1\n",
      "  (0, 6668)\t1\n",
      "  (0, 5830)\t1\n",
      "  (0, 17630)\t1\n",
      "  (0, 26911)\t1\n",
      "  (0, 4838)\t1\n",
      "  (0, 1560)\t1\n",
      "  (0, 15194)\t1\n",
      "  (0, 29913)\t1\n",
      "  (0, 16366)\t1\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet using the BoW feature space\n",
    "print(X_train_BoW[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the created vocabulary for the given dataset in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = BoW_vectorizer.vocabulary_\n",
    "output_pd = pd.DataFrame(list(output_dict.items()),columns = ['word','count'])\n",
    "\n",
    "output_pd.T.to_csv('BoW-vocab.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TFIDF\n",
    "In this approach, we use the **TfidfVectorizer** library to separate all the words in this corpus (dataset). Same as the BoW approach, these words are then used as the 'vectors' or 'features' to represent each instance (Tweet).\n",
    "\n",
    "However, in this method for each instance the value associated with each 'vector' (word) is not the number of times the word repeated in that tweet, but the TFIDF value of then 'voctor' (word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using TFIDF): (20711, 30126)\n",
      "Test feature space size (using TFIDF): (1091, 30126)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Train feature space size (using TFIDF):\",X_train_BoW.shape)\n",
    "print(\"Test feature space size (using TFIDF):\",X_test_BoW.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16366)\t0.5860882228462222\n",
      "  (0, 29913)\t0.17589630634099077\n",
      "  (0, 15194)\t0.22839016001792783\n",
      "  (0, 1560)\t0.19575906631021145\n",
      "  (0, 4838)\t0.25894906703086046\n",
      "  (0, 26911)\t0.2860805860886641\n",
      "  (0, 17630)\t0.15248928110796536\n",
      "  (0, 5830)\t0.2217932059675435\n",
      "  (0, 6668)\t0.34429029424948393\n",
      "  (0, 10987)\t0.32772901731539383\n",
      "  (0, 16557)\t0.29629944920099127\n"
     ]
    }
   ],
   "source": [
    "#Let's see one example tweet using the TFIDF feature space\n",
    "print(X_train_tfidf[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model 0R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     12659\n",
      "positive     5428\n",
      "negative     3715\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Build 0R\n",
    "\n",
    "#split training dataset into 3 class, possitive, negative and neutral\n",
    "\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "positive_set = train_data [(train_data [\"sentiment\"] == 'positive')]\n",
    "neutral_set = train_data [(train_data [\"sentiment\"] == 'neutral')]\n",
    "negative_set = train_data [(train_data [\"sentiment\"] == 'negative')]\n",
    "print(train_data[\"sentiment\"].value_counts())\n",
    "\n",
    "#find the class with the most instance\n",
    "max_size = len(positive_set)\n",
    "max_dataset = positive_set\n",
    "for data_set in [neutral_set, negative_set]:\n",
    "    if len(data_set) > max_size:\n",
    "        max_dataset = data_set\n",
    "        max_size = len(data_set)\n",
    "\n",
    "# the model will use the class with the most instance to classify all of the test data\n",
    "chosen_class = max_dataset.iloc[0][\"sentiment\"]\n",
    "\n",
    "# classify test set\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')\n",
    "test_data['sentiment'] = chosen_class\n",
    "(test_data.drop(['text'], axis=1)).to_csv('base.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.10      0.18       183\n",
      "     neutral       0.60      0.92      0.73       609\n",
      "    positive       0.69      0.29      0.41       299\n",
      "\n",
      "    accuracy                           0.61      1091\n",
      "   macro avg       0.63      0.44      0.44      1091\n",
      "weighted avg       0.63      0.61      0.55      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "BNBmodel = BernoulliNB()\n",
    "BNBmodel.fit(X_train_tfidf, y_train)\n",
    "y_pred = BNBmodel.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.42      0.47       183\n",
      "     neutral       0.66      0.78      0.72       609\n",
      "    positive       0.64      0.49      0.55       299\n",
      "\n",
      "    accuracy                           0.64      1091\n",
      "   macro avg       0.62      0.56      0.58      1091\n",
      "weighted avg       0.64      0.64      0.63      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "SVMmodel = LinearSVC()\n",
    "SVMmodel.fit(X_train_tfidf, y_train)\n",
    "y_pred2 = SVMmodel.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.04      0.08       183\n",
      "     neutral       0.60      0.92      0.72       609\n",
      "    positive       0.67      0.31      0.42       299\n",
      "\n",
      "    accuracy                           0.60      1091\n",
      "   macro avg       0.59      0.42      0.41      1091\n",
      "weighted avg       0.60      0.60      0.53      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest_model=RandomForestClassifier(n_estimators=100)\n",
    "random_forest_model.fit(X_train_tfidf, y_train)\n",
    "y_pred3 = random_forest_model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_8812/635345592.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Quang\\AppData\\Local\\Temp/ipykernel_8812/635345592.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    y_pred = model.predict(X_test)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def model_Evaluate(model):\n",
    "# Predict values for Test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "# Print the evaluation metrics for the dataset.\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Compute and plot the Confusion matrix\n",
    "# cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# categories = ['Negative','Positive']\n",
    "# group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    "# group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "# labels = [f'{v1}n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
    "# labels = np.asarray(labels).reshape(2,2)\n",
    "# sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    "# xticklabels = categories, yticklabels = categories)\n",
    "# plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    "# plt.ylabel(\"Actual values\" , fontdict = {'size':14}, labelpad = 10)\n",
    "# plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "447fbe3803a1e5da9818dba51e35bc9e19d5aad10b584a5baf76caa68c0e298b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
