{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Train.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s',\n",
    "              'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "STOPWORDS = set(stopwordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happi cute taco ran cri #thisisu akjsbg ! ! ! ! ! ? ? ? ? #\n"
     ]
    }
   ],
   "source": [
    "tweet = 'This is happiness cute. the about tacos ran crying #thisisus @nbcthisisus https://t.co/ndxqyl4gjk AKJSBG !!! on !! ???? 1029468798346y 368258 .,/, $#%$'\n",
    "def preprocess_string(str):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    porter = PorterStemmer()\n",
    "\n",
    "    str = str.lower()\n",
    "    str = re.sub(r'@[^\\s]+','',str)\n",
    "    str = re.sub(r'((www.[^s]+)|(https?://[^\\s]+))',' ',str)\n",
    "    str = re.sub(r'[^a-zA-Z!?#S]',' ',str)\n",
    "    str = re.sub(r'\\b\\w{1,2}\\b', '', str)\n",
    "    str = re.sub(r'!', ' ! ', str)\n",
    "    str = re.sub(r'\\?', ' ? ', str)\n",
    "    str = \" \".join([word for word in str.split() if word not in STOPWORDS])\n",
    "    str = str.split()\n",
    "    # blob_object = TextBlob(str)\n",
    "    # str = blob_object.words (this removes all puncuations)\n",
    "\n",
    "    # str = [lemmatizer.lemmatize(x) for x in str]\n",
    "    str = [porter.stem(x) for x in str]\n",
    "    str = ' '.join(str)\n",
    "    return str\n",
    "\n",
    "print(preprocess_string(tweet))\n",
    "\n",
    "data['text'] = data['text'].apply(lambda text: preprocess_string(text))\n",
    "# data.to_csv('preprocessed-train-data.csv', index=False)\n",
    "\n",
    "X = data.text\n",
    "y = data.sentiment\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=76)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_sent = list(X_train_raw)\n",
    "\n",
    "# words = {}\n",
    "# for el in list_of_sent:\n",
    "#     el = el.split()\n",
    "#     for el2 in el:\n",
    "#         if el2 not in words:\n",
    "#             words[el2] = 1\n",
    "#         else:\n",
    "#             words[el2] += 1\n",
    "\n",
    "# for (k, v) in words.items():\n",
    "#     if v <= 1:\n",
    "#         print (k, v)\n",
    "# def remove_single_appearance_word(sent, words):\n",
    "#     sent = sent.split()\n",
    "#     for el in sent:\n",
    "#         if el not in words:\n",
    "#             sent.remove(el)\n",
    "#         if el in words:\n",
    "#             if words[el] <= 5 :\n",
    "#                 sent.remove(el)\n",
    "#     return ' '.join(sent)\n",
    "\n",
    "# X_train_raw = X_train_raw.apply(remove_single_appearance_word, args=(words,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using BoW): (20711, 3432)\n",
      "Test feature space size (using BoW): (1091, 3432)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "BoW_vectorizer = CountVectorizer(max_df=0.80, min_df=7)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_raw)\n",
    "\n",
    "print(\"Train feature space size (using BoW):\",X_train_BoW.shape)\n",
    "print(\"Test feature space size (using BoW):\",X_test_BoW.shape)\n",
    "\n",
    "output_dict = BoW_vectorizer.vocabulary_\n",
    "output_pd = pd.DataFrame(list(output_dict.items()),columns = ['word','count'])\n",
    "\n",
    "output_pd.T.to_csv('BoW-vocab.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using TFIDF): (20711, 4286)\n",
      "Test feature space size (using TFIDF): (1091, 4286)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=5, max_features=5000)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "print(\"Train feature space size (using TFIDF):\",X_train_tfidf.shape)\n",
    "print(\"Test feature space size (using TFIDF):\",X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                               text\n",
      "0     802217876644052000  putin abduct ukrainian citizen occupi territor...\n",
      "1     802425296955682000  putin want interven would donat clinton founda...\n",
      "2     805664502515662000                                  elsewher progland\n",
      "3     639928670103015000  femal cop gucci foamposit tomorrow ? checkout ...\n",
      "4     673824182287904000  news great saturday town old uni friend david ...\n",
      "...                  ...                                                ...\n",
      "6094  662664783083122000  ticket see vamp april tri fan project sign hold ?\n",
      "6095  635582180316479000  may seen but john cena given make wish gift ki...\n",
      "6096  805537394262994000                     democraci look like like share\n",
      "6097  640586501571637000  damn shawn right may conced win alon even numb...\n",
      "6098  802428434588827000  white liber make sick like ancestor weren dict...\n",
      "\n",
      "[6099 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('Test.csv', sep=',')\n",
    "test_data['text'] = test_data['text'].apply(lambda text: preprocess_string(text))\n",
    "X_real_test_raw = test_data.text\n",
    "X_real_test_tfidf = tfidf_vectorizer.transform(X_real_test_raw)\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.26      0.39       181\n",
      "     neutral       0.69      0.91      0.79       659\n",
      "    positive       0.72      0.46      0.56       251\n",
      "\n",
      "    accuracy                           0.70      1091\n",
      "   macro avg       0.72      0.54      0.58      1091\n",
      "weighted avg       0.71      0.70      0.67      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "SVMmodel = SVC()\n",
    "o_vs_r = OneVsOneClassifier(SVMmodel)\n",
    "\n",
    "# o_vs_r.fit(X_train_BoW, y_train)\n",
    "# y_pred_svm_BoW = o_vs_r.predict(X_test_BoW)\n",
    "\n",
    "# cf=classification_report(y_test,y_pred_svm_BoW)\n",
    "# print(cf)\n",
    "\n",
    "o_vs_r.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm_tfidf = o_vs_r.predict(X_test_tfidf)\n",
    "\n",
    "cf=classification_report(y_test,y_pred_svm_tfidf)\n",
    "print(cf)\n",
    "\n",
    "y_pred_real_svm_tfidf = o_vs_r.predict(X_real_test_tfidf)\n",
    "data = {'id':test_data.id,'text':X_real_test_raw,'sentiment':y_pred_real_svm_tfidf}\n",
    "predictions = pd.DataFrame(data=data)\n",
    "(predictions.drop(['text'], axis=1)).to_csv('svm-model-tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.39      0.49       181\n",
      "     neutral       0.72      0.86      0.78       659\n",
      "    positive       0.67      0.55      0.60       251\n",
      "\n",
      "    accuracy                           0.71      1091\n",
      "   macro avg       0.69      0.60      0.63      1091\n",
      "weighted avg       0.70      0.71      0.69      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# LRmodel.fit(X_train_BoW, y_train)\n",
    "# y_pred_svm_BoW = LRmodel.predict(X_test_BoW)\n",
    "\n",
    "# cf=classification_report(y_test,y_pred_svm_BoW)\n",
    "# print(cf)\n",
    "\n",
    "LRmodel.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm_tfidf = LRmodel.predict(X_test_tfidf)\n",
    "\n",
    "cf=classification_report(y_test,y_pred_svm_tfidf)\n",
    "print(cf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.20      0.32       181\n",
      "     neutral       0.67      0.91      0.77       659\n",
      "    positive       0.67      0.37      0.48       251\n",
      "\n",
      "    accuracy                           0.67      1091\n",
      "   macro avg       0.68      0.50      0.52      1091\n",
      "weighted avg       0.67      0.67      0.63      1091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "BNBmodel = MultinomialNB()\n",
    "\n",
    "# BNBmodel.fit(X_train_BoW, y_train)\n",
    "# y_pred_svm_BoW = BNBmodel.predict(X_test_BoW)\n",
    "\n",
    "# cf=classification_report(y_test,y_pred_svm_BoW)\n",
    "# print(cf)\n",
    "\n",
    "BNBmodel.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm_tfidf = BNBmodel.predict(X_test_tfidf)\n",
    "\n",
    "cf=classification_report(y_test,y_pred_svm_tfidf)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_real_lr_tfidf = LRmodel.predict(X_real_test_tfidf)\n",
    "data = {'id':test_data.id,'text':X_real_test_raw,'sentiment':y_pred_real_lr_tfidf}\n",
    "predictions = pd.DataFrame(data=data)\n",
    "(predictions.drop(['text'], axis=1)).to_csv('lr-model-tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_real_lr_tfidf = BNBmodel.predict(X_real_test_tfidf)\n",
    "data = {'id':test_data.id,'text':X_real_test_raw,'sentiment':y_pred_real_lr_tfidf}\n",
    "predictions = pd.DataFrame(data=data)\n",
    "(predictions.drop(['text'], axis=1)).to_csv('bnb-model-tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing required libraries\n",
    "# from sklearn.model_selection import KFold \n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from numpy import mean\n",
    "# from numpy import std\n",
    "\n",
    "# # k = 5\n",
    "# # kf = KFold(n_splits=k, random_state=None)\n",
    "# # model = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    " \n",
    "# # acc_score = []\n",
    " \n",
    "# # for train_index , test_index in kf.split(X_train_tfidf):\n",
    "# #     X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "# #     y_train , y_test = y[train_index] , y[test_index]\n",
    "     \n",
    "# #     model.fit(X_train,y_train)\n",
    "# #     pred_values = model.predict(X_test)\n",
    "     \n",
    "# #     acc = accuracy_score(pred_values , y_test)\n",
    "# #     acc_score.append(acc)\n",
    "     \n",
    "# # avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "# # print('accuracy of each fold - {}'.format(acc_score))\n",
    "# # print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "\n",
    "# cv = KFold(n_splits=100, random_state=1, shuffle=True)\n",
    "# # create model\n",
    "# model = LogisticRegression()\n",
    "# # evaluate model\n",
    "# scores = cross_val_score(model, X_train_tfidf, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# # report performance\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compare ensemble to each baseline classifier\n",
    "# from numpy import mean\n",
    "# from numpy import std\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "# from matplotlib import pyplot\n",
    " \n",
    "# # get a stacking ensemble of models\n",
    "# def get_stacking():\n",
    "# \t# define the base models\n",
    "# \tlevel0 = list()\n",
    "# \tlevel0.append(('lr', LogisticRegression(multi_class='multinomial')))\n",
    "# \tlevel0.append(('bayes', MultinomialNB()))\n",
    "# \tlevel0.append(('rf', RandomForestClassifier(n_estimators=200, random_state=0)))\n",
    "# \t# define meta learner model\n",
    "# \tlevel1 = LogisticRegression(multi_class='multinomial')\n",
    "# \t# define the stacking ensemble\n",
    "# \tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "# \treturn model\n",
    " \n",
    "# # get a list of models to evaluate\n",
    "# def get_models():\n",
    "# \tmodels = dict()\n",
    "# \tmodels['lr'] = LogisticRegression(multi_class='multinomial')\n",
    "# \tmodels['bayes'] = MultinomialNB()\n",
    "# \tmodels['rf']= RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "# \tmodels['stacking'] = get_stacking()\n",
    "# \treturn models\n",
    " \n",
    "# # evaluate a give model using cross-validation\n",
    "# def evaluate_model(model, X, y):\n",
    "# \tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# \tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# \treturn scores\n",
    " \n",
    "# # define dataset\n",
    "# X = X_train_tfidf\n",
    "# y = y_train\n",
    "# # get the models to evaluate\n",
    "# models = get_models()\n",
    "# # evaluate the models and store results\n",
    "# results, names = list(), list()\n",
    "# for name, model in models.items():\n",
    "# \tscores = evaluate_model(model, X, y)\n",
    "# \tresults.append(scores)\n",
    "# \tnames.append(name)\n",
    "# \tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# # plot model performance for comparison\n",
    "# pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "# pyplot . show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "447fbe3803a1e5da9818dba51e35bc9e19d5aad10b584a5baf76caa68c0e298b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
